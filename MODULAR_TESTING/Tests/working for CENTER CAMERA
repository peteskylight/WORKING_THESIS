import cv2
import numpy as np
from ultralytics import YOLO

# Initialize YOLO model
model = YOLO('yolov8n.pt')  # Use any YOLOv8 model variant as per your requirement

# Define constants
VIDEO_PATH = r"C:\Users\Bennett\Documents\WORKING_THESIS\RESOURCES\Examination Sample Videos\Shorter.mp4"  # Replace with your video path
OUTPUT_VIDEO_PATH = r"C:\Users\Bennett\Documents\WORKING_THESIS\RESOURCES\OUTPUT DYNAMIC\sample.mp4"
FPS = 30  # Assuming 30 FPS, adjust based on your video
MASK_COLOR = (0, 0, 0)  # Black color for masking

# Define ROI height from the top
ROI_HEIGHT = 860  # Height of the ROI from the top (adjust as needed)

# Define ROI for the top portion of the frame
def create_roi_mask(frame, roi_height):
    height, width, _ = frame.shape
    mask = np.zeros((height, width), dtype=np.uint8)
    
    # Define the ROI as the top portion of the frame
    roi = (0, 0, width, roi_height)  # Top to bottom with specified height

    # Create a filled rectangle for ROI
    cv2.rectangle(mask, (roi[0], roi[1]), (roi[2], roi[3]), 255, -1)
    cv2.imshow("test", mask)
    return mask

# Process video
cap = cv2.VideoCapture(VIDEO_PATH)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, FPS, (frame_width, frame_height))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Create ROI mask for the top portion of the frame
    roi_mask = create_roi_mask(frame, ROI_HEIGHT)

    # Combine the mask with the original image for detection
    masked_frame = cv2.bitwise_and(frame, frame, mask=roi_mask)

    # Apply YOLO model on the masked frame
    results = model(masked_frame)

    # Create a copy of the frame for drawing
    output_frame = frame.copy()

    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy()  # Bounding box coordinates
        confidences = result.boxes.conf.cpu().numpy()  # Confidence scores
        class_ids = result.boxes.cls.cpu().numpy()  # Class IDs

        for box, confidence, class_id in zip(boxes, confidences, class_ids):
            x1, y1, x2, y2 = map(int, box)

            # Clip the bounding box to the ROI
            y1 = max(y1, 0)  # Clip the top of the bounding box to the frame boundary
            y2 = min(y2, ROI_HEIGHT)  # Clip the bottom of the bounding box to the ROI boundary

            # Check if the adjusted bounding box is valid
            if y1 >= y2:  # Invalid bounding box (e.g., fully outside the ROI after adjustment)
                continue

            # Draw bounding boxes on the output frame
            cv2.rectangle(output_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"{model.names[int(class_id)]} {confidence:.2f}"
            cv2.putText(output_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Write the processed frame to output
    out.write(output_frame)

    # Display the frame
    #cv2.imshow('YOLO Detection', output_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()